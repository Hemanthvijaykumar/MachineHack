{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lasting-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worst-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adverse-norman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b0',\n",
       " 'b1',\n",
       " 'b2',\n",
       " 'n0',\n",
       " 'n1',\n",
       " 'n2',\n",
       " 'n3',\n",
       " 'n4',\n",
       " 'c0_0',\n",
       " 'c0_1',\n",
       " 'c0_2',\n",
       " 'c0_3',\n",
       " 'c0_4',\n",
       " 'c0_5',\n",
       " 'c0_6',\n",
       " 'c1_0',\n",
       " 'c1_1',\n",
       " 'c1_2',\n",
       " 'c1_3',\n",
       " 'c1_4',\n",
       " 'c1_5',\n",
       " 'c1_6',\n",
       " 'c1_7',\n",
       " 'c1_8',\n",
       " 'c1_9',\n",
       " 'c1_10',\n",
       " 'c1_11',\n",
       " 'c2_0',\n",
       " 'c2_1',\n",
       " 'c2_2',\n",
       " 'c2_3',\n",
       " 'c2_4',\n",
       " 'c2_5',\n",
       " 'c2_6',\n",
       " 'c2_7',\n",
       " 'c3_0',\n",
       " 'c3_1',\n",
       " 'c3_2',\n",
       " 'c3_3',\n",
       " 'c3_4',\n",
       " 'c3_5',\n",
       " 'c3_6',\n",
       " 'c3_7',\n",
       " 'c3_8',\n",
       " 'c3_9',\n",
       " 'c3_10',\n",
       " 'c3_11',\n",
       " 'c4_0',\n",
       " 'c4_1',\n",
       " 'c4_2',\n",
       " 'c4_3',\n",
       " 'c4_4',\n",
       " 'c4_5',\n",
       " 'c4_6',\n",
       " 'c4_7',\n",
       " 'c4_8',\n",
       " 'c4_9',\n",
       " 'c4_10',\n",
       " 'c4_11',\n",
       " 'c4_12',\n",
       " 'c5_0',\n",
       " 'c5_1',\n",
       " 'c5_2',\n",
       " 'c5_3',\n",
       " 'c5_4',\n",
       " 'c5_5',\n",
       " 'c5_6',\n",
       " 'c5_7',\n",
       " 'c5_8',\n",
       " 'c6_0',\n",
       " 'c6_1',\n",
       " 'c6_2',\n",
       " 'c6_3',\n",
       " 'c6_4',\n",
       " 'c6_5',\n",
       " 'c6_6',\n",
       " 'c6_7']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_data(df):\n",
    "    \n",
    "    df['gill-attachment'] = df['gill-attachment'].fillna('z')\n",
    "    df['ring-type'] = df['ring-type'].fillna('a')\n",
    "    df['season'] = df['season'].fillna('z')\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    #---CAT---#\n",
    "    data['c0'] = df['cap-shape'].map({'x':0, 'f':1, 's':2, 'b':3, 'o':4, 'p':5, 'c':6})\n",
    "    \n",
    "    data['c1'] = df['cap-color'].map({'n':0, 'y':1, 'w':2, 'g':3, 'e':4, 'o':5, 'r':6,\n",
    "                                      'u':7, 'p':8, 'k':9, 'b':10, 'l':11})\n",
    "    \n",
    "    data['c2'] = df['gill-attachment'].map({'a':0, 'd':1, 'x':2, 'p':3, 's':4, 'e':5, 'f':6, 'z':7})\n",
    "    \n",
    "    data['c3'] = df['gill-color'].map({'w':0, 'n':1, 'y':2, 'p':3, 'g':4, 'f':5, 'o':6,\n",
    "                                       'k':7, 'r':8, 'e':9, 'b':10, 'u':11})\n",
    "    \n",
    "    data['c4'] = df['stem-color'].map({'w':0, 'n':1, 'y':2, 'g':3, 'o':4, 'e':5, 'u':6,\n",
    "                                       'f':7, 'p':8, 'k':9, 'r':10, 'l':11, 'b':12})\n",
    "    \n",
    "    data['c5'] = df['ring-type'].map({'f':0, 'e':1, 'z':2, 'l':3, 'r':4, 'p':5, 'g':6, 'm':7, 'a':8})\n",
    "    \n",
    "    data['c6'] = df['habitat'].map({'d':0, 'g':1, 'l':2, 'm':3, 'h':4, 'p':5, 'w':6, 'u':7})\n",
    "    \n",
    "    #---BIN---#\n",
    "    data['b0'] = df['edible-poisonous'].map({'p':1, 'e':0})\n",
    "    data['b1'] = df['does-bruise-or-bleed'].map({'t':1, 'f':0})\n",
    "    data['b2'] = df['has-ring'].map({'t':1, 'f':0})\n",
    "    \n",
    "    \n",
    "    #---NUM---#\n",
    "    data['n0'] = (df['cap-diameter'] - 30) / 30.0\n",
    "    data['n1'] = (df['stem-height'] - 10) / 20.0\n",
    "    data['n2'] = (df['stem-width'] - 40) / 60.0\n",
    "    data['n3'] = data['n0'] / data['n2']\n",
    "    data['n4'] = data['n1'] / data['n2']\n",
    "    \n",
    "    data['n3'] = data['n3'].replace([np.inf, -np.inf], 0.0) / 400\n",
    "    data['n4'] = data['n4'].replace([np.inf, -np.inf], 0.0) / 400\n",
    "    \n",
    "    data['y'] = df['season'].map({'a':0, 'u':1, 'w':2, 's':3, 'z':-1})\n",
    "    \n",
    "    return data.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "\n",
    "data = create_data(data)\n",
    "test = create_data(test) \n",
    "\n",
    "cols = [f'c{i}' for i in range(7)] + ['b0', 'b1', 'b2'] + ['n0', 'n1', 'n2', 'n3', 'n4']\n",
    "\n",
    "data = pd.get_dummies(data, columns=[f'c{i}' for i in range(7)])\n",
    "test = pd.get_dummies(test, columns=[f'c{i}' for i in range(7)])\n",
    "\n",
    "cols = data.columns.to_list()\n",
    "cols.remove('y')\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-lemon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "SEED :  455\n",
      "---------------------------------------\n",
      "FOLD :  0\n",
      "Stop training because you reached max_epochs = 1 with best_epoch = 0 and best_valid_accuracy = 0.49368\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLD :  1\n",
      "Stop training because you reached max_epochs = 1 with best_epoch = 0 and best_valid_accuracy = 0.49368\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLD :  2\n",
      "Stop training because you reached max_epochs = 1 with best_epoch = 0 and best_valid_accuracy = 0.49368\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLD :  3\n",
      "Stop training because you reached max_epochs = 1 with best_epoch = 0 and best_valid_accuracy = 0.49362\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLD :  4\n",
      "Stop training because you reached max_epochs = 1 with best_epoch = 0 and best_valid_accuracy = 0.49362\n",
      "Best weights from best epoch are automatically used!\n",
      "---------------------------------------\n",
      "SEED :  485\n",
      "---------------------------------------\n",
      "FOLD :  0\n"
     ]
    }
   ],
   "source": [
    "N_folds = 5\n",
    "seeds = [455, 485, 659, 16, 5659]\n",
    "\n",
    "data_preds = np.zeros((data.shape[0], 4))\n",
    "test_preds = np.zeros((test.shape[0], 4))\n",
    "\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "for seed in seeds:\n",
    "    print('---------------------------------------')\n",
    "    print('SEED : ', seed)\n",
    "    print('---------------------------------------')\n",
    "    \n",
    "    \n",
    "    data['fold'] = -1\n",
    "    skf = StratifiedKFold(n_splits=N_folds, shuffle=True, random_state=seed)\n",
    "    for f, (_, idxs) in enumerate(skf.split(data, data['y'])):\n",
    "        data.loc[idxs, 'fold'] = f\n",
    "        \n",
    "    for F in range(N_folds):\n",
    "        \n",
    "        print('FOLD : ', F)\n",
    "        \n",
    "        train = data[data['fold'] != F].reset_index(drop=True)\n",
    "        valid = data[data['fold'] == F].reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        model = TabNetClassifier(verbose=0,seed=42)\n",
    "        model.fit(X_train=train[cols].values, y_train=train['y'].values,\n",
    "                  eval_set=[(train[cols].values, train['y'].values), (valid[cols].values, valid['y'].values)],\n",
    "                  eval_name=['train', 'valid'],\n",
    "                 patience=5, max_epochs=100,\n",
    "                 eval_metric=['accuracy'],\n",
    "                 batch_size=1024, virtual_batch_size=256)\n",
    "        \n",
    "        \n",
    "        preds = model.predict_proba(valid[cols].values)\n",
    "        \n",
    "        preds = model.predict_proba(test[cols].values)\n",
    "        test_preds += preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preds = data_preds / (len(seeds))\n",
    "test_preds = test_preds / (len(seeds) * N_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['season'] = np.argmax(test_preds, axis = 1)\n",
    "sub['season'] = sub['season'].map({0:'a', 1:'u', 2:'w', 3:'s'})\n",
    "sub.to_csv('tab.csv', index=False)\n",
    "sub['season'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tab0_oof.npy', data_preds)\n",
    "np.save('tab0_preds.npy', test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
